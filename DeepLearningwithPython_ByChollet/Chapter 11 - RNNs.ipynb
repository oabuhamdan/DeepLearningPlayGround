{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "“Every time I fire a linguist, the performance of the speech recognizer goes up.” - Frederick Jelinek:1990\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d533199b41527099"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What is NLP about?\n",
    "Using machine learning and large datasets to give computers the ability not to understand language, which is a more lofty goal, but to ingest a piece of language as input and return something useful\n",
    "\n",
    "Examples:\n",
    "- “What’s the topic of this text?” (text classification)\n",
    "- “Does this text contain abuse?” (content filtering)\n",
    "- “Does this text sound positive or negative?” (sentiment analysis)\n",
    "- “What should be the next word in this incomplete sentence?” (language modeling)\n",
    "- “How would you say this in German?” (translation)\n",
    "- “How would you summarize this article in one paragraph?” (summarization)\n",
    "etc.\n",
    "\n",
    "## NLP Evolution: \n",
    "1. The toolset of NLP—decision trees, logistic regression—only saw slow evolution from the 1990s to the early 2010s. Most of the research focus was on feature engineering.\n",
    "2. Then from 2015 to 2017, recurrent neural networks dominated the booming NLP scene. Bidirectional LSTM models, in particular, set the state of the art on many important tasks\n",
    "3. Around 2017–2018, a new architecture rose to replace RNNs: the Transformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55e43565f3bb41b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.2 Preparing text data\n",
    "Deep learning models, being differentiable functions, can only process numeric tensors: they can’t take raw text as input. Vectorizing text is the process of transforming text into numeric tensors. Text vectorization processes come in many shapes and forms, but they all follow the same template:\n",
    "\n",
    "1. First, you standardize the text to make it easier to process, such as by converting it to lowercase or removing punctuation.\n",
    "2. You split the text into units (called tokens), such as characters, words, or groups of words. This is called tokenization.\n",
    "3. You convert each such token into a numerical vector. This will usually involve first indexing all tokens present in the data.\n",
    "\n",
    "![alt text](static/text_vectorization.png \"text_vector\")\n",
    "\n",
    "### 1- Text Standardization\n",
    "Text standardization is a basic form of feature engineering that aims to erase encoding differences that you don’t want your model to have to deal with\n",
    "1. Remove punctuation marks.\n",
    "2. All to lower case.\n",
    "3. Transform non-standard characters to standard characters.\n",
    "4. Stemming: converting variations of terms into a single shared representation. Example: caught/been catching/catches -> [catch]\n",
    "\n",
    "A full example:\n",
    "{sunset came. i was staring at the Mexico sky. Isnt nature splendid??}\n",
    "will be\n",
    "{sunset came i [stare] at the mexico sky isnt nature splendid}\n",
    "\n",
    "**IMPORTANT NOTE:**\n",
    "This doesn't always apply to every context. For example, if you are classifying questions, '?' will be treated as a single token!\n",
    "\n",
    "### 2- Text Splitting (tokenization)\n",
    "**Ways of tokenization:**\n",
    "- Word-level tokenization: Where tokens are space-separated (or punctuation-separated) substrings. A variant of this is to further split words into subwords when applicable—for instance, treating “staring” as “star+ing” or “called” as “call+ed.”\n",
    "- N-gram tokenization: Where tokens are groups of N consecutive words. For instance, “the cat” or “he was” would be 2-gram tokens (also called bigrams).\n",
    "- Character-level tokenization: Where each character is its own token. In practice, this scheme is rarely used, and you only really see it in specialized contexts, like text generation or speech recognition.\n",
    "\n",
    "#### Types of Text Processing Models:\n",
    "Sequence Models: Models that care about order. Use word-level tokenization.\n",
    "\n",
    "Bag-of-Words models: treat input words as a set, discarding their original order. Use N-gram tokenization.\n",
    "N-grams are a way to artificially inject a small amount of local word order information into the model.\n",
    "\n",
    "**Understanding N-grams and bag-of-words**\n",
    "Word N-grams are groups of N (or fewer) consecutive words that you can extract from a sentence. The same concept may also be applied to characters instead of words. For Example:\n",
    "“the cat sat on the mat.” It may be decomposed into the following set of 2-grams:\n",
    "{\"the\", \"the cat\", \"cat\", \"cat sat\", \"sat\", \"sat on\", \"on\", \"on the\", \"the mat\", \"mat\"}\n",
    "\n",
    "It may also be decomposed into the following set of 3-grams:\n",
    "{\"the\", \"the cat\", \"cat\", \"cat sat\", \"the cat sat\", \"sat\", \"sat on\", \"on\", \"cat sat on\", \"on the\", \"sat on the\", \"the mat\", \"mat\", \"on the mat\"}\n",
    "\n",
    "Because bag-of-words isn’t an order-preserving tokenization method (the tokens generated are understood as a set, not a sequence, and the general structure of the sentences is lost), it tends to be used in shallow language-processing models rather than in deep learning models.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### 3- Vocabulary Indexing :\n",
    "It is building an index of all terms found in the training data (the “vocabulary”), and assign a unique integer to each entry in the vocabulary.\n",
    "You can then convert that integer into a vector encoding that can be processed by a neural network, like a one-hot vector.\n",
    "\n",
    "**Note:** that at this step it’s common to restrict the vocabulary to only the top 20,000 or 30,000 most common words found in the training data. Any text dataset tends to feature an extremely large number of unique terms, most of which only show up once or twice—indexing those rare terms would result in an excessively large feature space, where most features would have almost no information content.\n",
    "\n",
    "**What if we passed by a word that is not in the index?**\n",
    "To handle this, you should use an **“out of vocabulary” index (abbreviated as OOV index)**—a catch-all for any token that wasn't in the index. It’s usually index 1: you’re actually doing `token_index = vocabulary.get(token, 1)`. When decoding a sequence of integers back into words, you’ll replace 1 with something like “[UNK]” (which you’d call an “OOV token”)\n",
    "\n",
    "“Why use 1 and not 0?” you may ask. That’s because 0 is already taken. There are two special tokens that you will commonly use:\n",
    "- The OOV token (index 1): Not recognized word\n",
    "- The mask token (index 0): Used to pad sequences of data. Sequences should be in the same length."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "324bc77f54b15974"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import os, pathlib, shutil, random\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T00:47:20.548165Z",
     "start_time": "2024-07-15T00:46:52.383184Z"
    }
   },
   "id": "f094810a187bd8f3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 18:51:34.797073: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-07-13 18:51:34.797143: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-07-13 18:51:34.797160: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-07-13 18:51:34.797549: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-13 18:51:34.797590: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "text_vectorization = layers.TextVectorization(output_mode=\"int\")\n",
    "# output_mode: Configures the layer to return sequences of words encoded as integer indices"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T23:51:34.862920Z",
     "start_time": "2024-07-13T23:51:13.192141Z"
    }
   },
   "id": "610676b155f85a20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, the TextVectorization layer will use the setting “convert to lowercase and remove punctuation” for text standardization, and “split on whitespace” for tokenization. Note that such custom functions should operate on **tf.string** tensors, not regular Python strings!\n",
    "You can customize the standardization and the tokenization functions by passing it to the function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4977ef15b5f548c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that you can retrieve the computed vocabulary via get_vocabulary()—this can be useful if you need to convert text encoded as integer sequences back into words. The first two entries in the vocabulary are the mask token (index 0) and the OOV token (index 1). Entries in the vocabulary list are sorted by frequency,so with a real-world dataset, very common words like “the” or “a” would come first."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "287f051ff7c2be64"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n '[UNK]',\n 'erase',\n 'write',\n 'then',\n 'rewrite',\n 'poppy',\n 'i',\n 'blooms',\n 'and',\n 'again',\n 'a']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T17:43:38.236666Z",
     "start_time": "2024-07-12T17:43:38.227355Z"
    }
   },
   "id": "864b4b81f59818c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n",
      "i write rewrite and [UNK] rewrite again\n"
     ]
    }
   ],
   "source": [
    "# Full Example\n",
    "# Encode\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
    "encoded_sentence = text_vectorization(test_sentence)\n",
    "print(encoded_sentence)\n",
    "# Decode\n",
    "inverse_vocab = dict(enumerate(vocabulary))\n",
    "decoded_sentence = \" \".join(inverse_vocab[int(i)] for i in encoded_sentence)\n",
    "print(decoded_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T17:47:20.068009Z",
     "start_time": "2024-07-12T17:47:19.909325Z"
    }
   },
   "id": "b98cfc89b4e80ef0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Because TextVectorization is mostly a dictionary lookup operation, **it can’t be executed on a GPU (or TPU)—only on a CPU**. So if you’re training your model on a GPU, your TextVectorization layer will run on the CPU before sending its output to the GPU. \n",
    "\n",
    "There are two ways we could use our TextVectorization layer.\n",
    "1. The first option is to put it in the tf.data pipeline\n",
    "2. The second option is to make it part of the model (after all, it’s a Keras layer)\n",
    "\n",
    "There’s an important difference between the two:\n",
    "- In option 1, vectorization will happen synchronously with the rest of the model. This means that at each training step, the rest of the model (placed on the GPU) will have to wait for the output of the TextVectorization layer (placed on the CPU) to be ready in order to get to work.\n",
    "- In option 2, vectorization is asynchronous preprocessing on CPU: while the GPU runs the model on one batch of vectorized data, the CPU stays busy by vectorizing the next batch of raw strings.\n",
    "\n",
    "In production, there is a solution to handle raw input text. We'll discuss later in the chapter."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5480ddeefbdede5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 11.3 Two approaches for representing groups of words: Sets and sequences\n",
    "The problem of order in natural language is an interesting one: unlike the steps of a timeseries, words in a sentence don’t have a natural, canonical order.\n",
    "Order is clearly important, but its relationship to meaning isn’t straightforward.\n",
    "\n",
    "The Transformer architecture is technically order-agnostic, yet it injects word-position information into the representations it processes, which enables it to simultaneously look at different parts of a sentence (unlike RNNs) while still being order-aware. \n",
    "\n",
    "Because they take into account word order, both RNNs and Transformers are called **sequence models**\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b77afb720bab202"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparing the IMDB movie reviews data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59b8839592cc12e4"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 80.2M  100 80.2M    0     0  4882k      0  0:00:16  0:00:16 --:--:-- 9015k\r\n",
      "Warning: Got more output options than URLs\r\n",
      "tar: could not chdir to '/data'\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!curl -o data/aclImdb_v1.tar.gz -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T20:50:49.634040Z",
     "start_time": "2024-07-12T20:50:32.393269Z"
    }
   },
   "id": "6fff10bc96f65d1a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "!tar -xf data/aclImdb_v1.tar.gz -C ./data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T20:57:42.080538Z",
     "start_time": "2024-07-12T20:56:25.843656Z"
    }
   },
   "id": "2c610c6ba20e412c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "# look at the data\n",
    "!cat data/aclImdb/train/pos/4077_10.txt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:02:03.259049Z",
     "start_time": "2024-07-12T21:02:03.043261Z"
    }
   },
   "id": "24a6dc705af0432b"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Let’s prepare a validation set by setting apart 20% of the training text files in a new directory, aclImdb/val:\n",
    "\n",
    "base_dir = pathlib.Path(\"data/aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "\n",
    "\n",
    "def create_val_files(category):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    random.seed(1337)\n",
    "    val_files = random.sample(files, num_val_samples)\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)\n",
    "\n",
    "\n",
    "create_val_files(\"neg\")\n",
    "create_val_files(\"pos\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:02:12.803888Z",
     "start_time": "2024-07-12T21:02:11.137058Z"
    }
   },
   "id": "a525dcbf84f0c70"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 19:47:21.450027: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-07-14 19:47:21.450053: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-07-14 19:47:21.450062: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-07-14 19:47:21.450226: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-14 19:47:21.450402: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "# text_dataset_from_directory: utility to create a batched Dataset of text and their labels for a directory structure\n",
    "# main_directory/\n",
    "# ...class_a/\n",
    "# ......a_text_1.txt\n",
    "# ......a_text_2.txt\n",
    "# ...class_b/\n",
    "# ......b_text_1.txt\n",
    "# ......b_text_2.txt\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"data/aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"data/aclImdb/val\", batch_size=batch_size\n",
    ")\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"data/aclImdb/test\", batch_size=batch_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T00:47:22.862624Z",
     "start_time": "2024-07-15T00:47:20.548041Z"
    }
   },
   "id": "c9e48b5d656cf654"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**keras.utils.text_dataset_from_directory**\n",
    "Generates a tf.data.Dataset from text files in a directory.\n",
    "\n",
    "**tf.data.Dataset** \n",
    "Has a map function.\n",
    "```\n",
    "map(\n",
    "    map_func, num_parallel_calls=None, deterministic=None, name=None\n",
    ")\n",
    "```\n",
    "This transformation applies map_func to each element of this dataset, and returns a new dataset containing the transformed elements, in the same order as they appeared in the input."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "581467050c6334f9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'tensorflow.python.data.ops.batch_op._BatchDataset'>\n",
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: b'I have seen this mov' ...\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Type:\", type(train_ds))\n",
    "inputs, targets = next(iter(train_ds))\n",
    "print(\"inputs.shape:\", inputs.shape)\n",
    "print(\"inputs.dtype:\", inputs.dtype)\n",
    "print(\"targets.shape:\", targets.shape)\n",
    "print(\"targets.dtype:\", targets.dtype)\n",
    "print(\"inputs[0]:\", inputs[0].numpy()[:20], \"...\")\n",
    "print(\"targets[0]:\", targets[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T23:53:17.389772Z",
     "start_time": "2024-07-13T23:53:17.349122Z"
    }
   },
   "id": "2ef9a700801bc262"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Processing words as a set: The bag-of-words approach\n",
    "The simplest way to encode a piece of text for processing by a machine learning model is to discard order and treat it as a set (a “bag”) of tokens. You could either look at individual words (unigrams), or try to recover some local order information by looking at groups of consecutive token (N-grams).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d7be791eef21c7c"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 0 ... 0 0 0], shape=(20000,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 16:19:22.833939: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Unigrams First\n",
    "# Treat each single word as a token by itself.\n",
    "text_vectorization = keras.layers.TextVectorization(max_tokens=20000,  # limit to 20,000 most frequent words\n",
    "                                                    output_mode=\"multi_hot\")\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)  # extract the text from the train dataset and ignore targets\n",
    "text_vectorization.adapt(text_only_train_ds)  # build the text vectorizer\n",
    "test_sentence = \"the movie is awesome\"\n",
    "encoded_sentence = text_vectorization(test_sentence)\n",
    "print(encoded_sentence)\n",
    "# notice that \"the\" is the second most popular term"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T21:19:22.942459Z",
     "start_time": "2024-07-13T21:19:16.763285Z"
    }
   },
   "id": "e9e7afd08ec6730b"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Getting the multi-hot encoded text and targets for train dataset\n",
    "binary_1gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "# getting the multi-hot encoded text and targets for test dataset\n",
    "binary_1gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "# getting the multi-hot encoded text and targets for val dataset\n",
    "binary_1gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:37:08.548645Z",
     "start_time": "2024-07-12T21:37:08.430236Z"
    }
   },
   "id": "5584e05b10872857"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1 1 1 ... 0 0 0], shape=(20000,), dtype=int64)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = next(iter(binary_1gram_train_ds))\n",
    "print(\"inputs.shape:\", inputs.shape)\n",
    "print(\"inputs.dtype:\", inputs.dtype)\n",
    "print(\"targets.shape:\", targets.shape)\n",
    "print(\"targets.dtype:\", targets.dtype)\n",
    "print(\"inputs[0]:\", inputs[0])  # all words encoded into a multi-hot encode \n",
    "print(\"targets[0]:\", targets[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:37:54.968925Z",
     "start_time": "2024-07-12T21:37:54.920513Z"
    }
   },
   "id": "ae889cb847c3fa4a"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    input_layer = keras.Input(shape=(max_tokens,))  # we don't specify batch size here because it's a dataset\n",
    "    x = keras.layers.Dense(hidden_dim, activation='relu')(input_layer)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    output = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:44:56.720004Z",
     "start_time": "2024-07-12T21:44:56.717522Z"
    }
   },
   "id": "2f48cc597afc2ec9"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.7556 - loss: 0.5075 - val_accuracy: 0.8936 - val_loss: 0.2828\n",
      "Epoch 2/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.8879 - loss: 0.3077 - val_accuracy: 0.8976 - val_loss: 0.2648\n",
      "Epoch 3/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9097 - loss: 0.2585 - val_accuracy: 0.8928 - val_loss: 0.2742\n",
      "Epoch 4/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9174 - loss: 0.2478 - val_accuracy: 0.8914 - val_loss: 0.2857\n",
      "Epoch 5/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9195 - loss: 0.2341 - val_accuracy: 0.8906 - val_loss: 0.2972\n",
      "Epoch 6/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9255 - loss: 0.2215 - val_accuracy: 0.8870 - val_loss: 0.3104\n",
      "Epoch 7/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9291 - loss: 0.2091 - val_accuracy: 0.8858 - val_loss: 0.3230\n",
      "Epoch 8/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9303 - loss: 0.2086 - val_accuracy: 0.8812 - val_loss: 0.3232\n",
      "Epoch 9/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9374 - loss: 0.1992 - val_accuracy: 0.8758 - val_loss: 0.3400\n",
      "Epoch 10/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9344 - loss: 0.2086 - val_accuracy: 0.8828 - val_loss: 0.3428\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x349afbed0>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"models/binary_1gram.keras\", save_best_only=True)]\n",
    "model.fit(x=binary_1gram_train_ds.cache(), validation_data=binary_1gram_val_ds.cache(), callbacks=callbacks, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:09.673974Z",
     "start_time": "2024-07-12T21:56:26.842886Z"
    }
   },
   "id": "622e09a41b9e9adc"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 15ms/step - accuracy: 0.8842 - loss: 0.2972\n",
      "Test acc: 0.884\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"models/binary_1gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T21:57:30.995095Z",
     "start_time": "2024-07-12T21:57:18.315544Z"
    }
   },
   "id": "601c3573a43c8d61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes on the Training cell:\n",
    "1. We call cache() on the datasets to cache them in memory: this way, we will only do the preprocessing once, during the first epoch, and we’ll reuse the preprocessed texts for the following epochs. This can only be done if the data is small enough to fit in memory.\n",
    "\n",
    "2. Q: Why we don't provide a batch size here?\n",
    "    Answer from the docs:\n",
    "    If unspecified, batch_size will default to 32. Do not specify the batch_size if your data is in the form of datasets, generators, or keras.utils.PyDataset instances (since they generate batches). \n",
    "3. Q: Why we don't provide y here?\n",
    "   Answer from docs: If x is a dataset, generator, or keras.utils.PyDataset instance, y should not be specified (since targets will be obtained from x). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "330a9cb134ababc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bigrams with binary encoding\n",
    "Most common type of N-Grams is Bigrams.\n",
    "The **TextVectorization layer** can be configured to return arbitrary N-grams: bigrams, trigrams, etc. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec4e3683ef3cee38"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 16:19:14.727557: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 0 ... 0 0 0], shape=(20000,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "bigram_text_vectorization = keras.layers.TextVectorization(ngrams=2, output_mode=\"multi_hot\", max_tokens=20000)\n",
    "bigram_text_vectorization.adapt(text_only_train_ds)\n",
    "test_sentence = \"the movie is awesome\"\n",
    "encoded_sentence = bigram_text_vectorization(test_sentence)\n",
    "print(encoded_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T21:19:16.282364Z",
     "start_time": "2024-07-13T21:19:07.288708Z"
    }
   },
   "id": "ac34a2350cd5314f"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "binary_2gram_train_ds = train_ds.map(lambda x, y: (bigram_text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_2gram_test_ds = test_ds.map(lambda x, y: (bigram_text_vectorization(x), y), num_parallel_calls=4)\n",
    "binary_2gram_val_ds = val_ds.map(lambda x, y: (bigram_text_vectorization(x), y), num_parallel_calls=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T23:58:23.542847Z",
     "start_time": "2024-07-12T23:58:23.482047Z"
    }
   },
   "id": "a6e0c230442fe927"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 10ms/step - accuracy: 0.7895 - loss: 0.4557 - val_accuracy: 0.9016 - val_loss: 0.2580\n",
      "Epoch 2/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9131 - loss: 0.2449 - val_accuracy: 0.9078 - val_loss: 0.2506\n",
      "Epoch 3/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9305 - loss: 0.2004 - val_accuracy: 0.9074 - val_loss: 0.2671\n",
      "Epoch 4/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9429 - loss: 0.1807 - val_accuracy: 0.9076 - val_loss: 0.2833\n",
      "Epoch 5/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9480 - loss: 0.1813 - val_accuracy: 0.9060 - val_loss: 0.2955\n",
      "Epoch 6/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9535 - loss: 0.1656 - val_accuracy: 0.9012 - val_loss: 0.3077\n",
      "Epoch 7/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9548 - loss: 0.1650 - val_accuracy: 0.9008 - val_loss: 0.3213\n",
      "Epoch 8/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9568 - loss: 0.1521 - val_accuracy: 0.8950 - val_loss: 0.3309\n",
      "Epoch 9/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9553 - loss: 0.1775 - val_accuracy: 0.8968 - val_loss: 0.3361\n",
      "Epoch 10/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9567 - loss: 0.1530 - val_accuracy: 0.8936 - val_loss: 0.3499\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x3a3153250>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"models/binary_2gram.keras\", save_best_only=True)]\n",
    "model.fit(x=binary_2gram_train_ds.cache(), validation_data=binary_2gram_val_ds.cache(), callbacks=callbacks, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T23:58:14.718644Z",
     "start_time": "2024-07-12T23:57:29.986810Z"
    }
   },
   "id": "4e0237bb661e26a9"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 4ms/step - accuracy: 0.8988 - loss: 0.2732\n",
      "Test acc: 0.900\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"models/binary_2gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-12T23:58:47.908336Z",
     "start_time": "2024-07-12T23:58:44.327944Z"
    }
   },
   "id": "150da2a1e74fc7e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bigrams with TF-IDF encoding\n",
    "You can also add a bit more information to this representation by counting how many times each word or N-gram occurs.\n",
    "```\n",
    "{\"the\": 2, \"the cat\": 1, \"cat\": 1, \"cat sat\": 1, \"sat\": 1,\n",
    " \"sat on\": 1, \"on\": 1, \"on the\": 1, \"the mat: 1\", \"mat\": 1}\n",
    "```\n",
    "If you’re doing text classification, knowing how many times a word occurs in a sample is critical: any sufficiently long movie review may contain the word “terrible” regardless of sentiment, but a review that contains many instances of the word “terrible” is likely a negative one.\n",
    "\n",
    "The words “the,” “a,” “is,” and “are” will always dominate your word count histograms, drowning out other words—despite being pretty much useless features in a classification context. How could we address this?\n",
    "**Normalization!** We could just normalize word counts by subtracting the mean and dividing by the variance.\n",
    "\n",
    "But... this method of normalization won't work in such a situation. It'll wreck the sparsity of the text vectors.\n",
    "Sparse Vector = [1, 1, 1, 0, 0, 0, 1] each one and zero here represents an existence of a word (1), or absence (0).\n",
    "Normalization will wreck the sparsity since Zero values might become non-Zeroes.\n",
    "\n",
    "***What to do then??***\n",
    "TF-IDF normalization. TF-IDF stands for “term frequency, inverse document frequency.”\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15dfb2d6a811887d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding TF-IDF\n",
    "The more a given term appears in a document, the more important that term is for understanding what the document is about.\n",
    "At the same time, the frequency at which the term appears across all documents in your dataset matters too: terms that appear in almost every document (like “the” or “a”) aren’t particularly informative, while terms that appear only in a small subset of all texts (like “Herzog”) are very distinctive,\n",
    "\n",
    "**TF-IDF** is a metric that fuses these two ideas. \n",
    "It weights a given term by taking “term frequency,” how many times the term appears in the current document, and dividing it by a measure of “document frequency” which estimates how often the term comes up across the dataset. \n",
    "\n",
    "```python\n",
    "def tfidf(term, document, dataset):\n",
    "    # Term Frequency (TF)\n",
    "    term_freq = document.count(term)\n",
    "    \n",
    "    # Total number of documents\n",
    "    total_docs = len(dataset)\n",
    "    \n",
    "    # Number of documents containing the term\n",
    "    doc_freq = sum(1 for doc in dataset if term in doc)\n",
    "    \n",
    "    # Inverse Document Frequency (IDF)\n",
    "    if doc_freq == 0:\n",
    "        idf = 0  # Handle the case where the term does not appear in any document\n",
    "    else:\n",
    "        idf = math.log(total_docs / doc_freq)\n",
    "    \n",
    "    # TF-IDF\n",
    "    tfidf_value = term_freq * idf\n",
    "    \n",
    "    return tfidf_value\n",
    "```\n",
    "High TF-IDF Value:\n",
    "A high TF-IDF value for a term in a particular document suggests that the term is highly relevant to that document. This is because the term appears frequently in that document (high term frequency) relative to how often it appears across all documents (low document frequency).\n",
    "\n",
    "Low TF-IDF Value:\n",
    "A low TF-IDF value indicates that the term is common across many documents in the corpus. It doesn't provide much discriminatory power in distinguishing one document from another.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14d650210b99add3"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 16:18:53.687823: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.         0.69727254 0.         ... 0.         0.         0.        ], shape=(20000,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tfidf_text_vectorization = keras.layers.TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"tf_idf\",\n",
    ")\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    tfidf_text_vectorization.adapt(text_only_train_ds)\n",
    "test_sentence = \"the movie is fantastic\"\n",
    "encoded_sentence = tfidf_text_vectorization(test_sentence)\n",
    "print(encoded_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T21:18:55.233544Z",
     "start_time": "2024-07-13T21:18:43.438108Z"
    }
   },
   "id": "757137996ae2d319"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "tfidf_2gram_train_ds = train_ds.map(lambda x, y: (bigram_text_vectorization(x), y), num_parallel_calls=4)\n",
    "tfidf_2gram_test_ds = test_ds.map(lambda x, y: (bigram_text_vectorization(x), y), num_parallel_calls=4)\n",
    "tfidf_2gram_val_ds = val_ds.map(lambda x, y: (bigram_text_vectorization(x), y), num_parallel_calls=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T02:14:13.315688Z",
     "start_time": "2024-07-13T02:14:13.211765Z"
    }
   },
   "id": "55df8e9478a77bc4"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 11ms/step - accuracy: 0.7976 - loss: 0.4536 - val_accuracy: 0.9038 - val_loss: 0.2468\n",
      "Epoch 2/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9140 - loss: 0.2398 - val_accuracy: 0.9060 - val_loss: 0.2456\n",
      "Epoch 3/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9286 - loss: 0.2038 - val_accuracy: 0.9078 - val_loss: 0.2549\n",
      "Epoch 4/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 7ms/step - accuracy: 0.9433 - loss: 0.1801 - val_accuracy: 0.9064 - val_loss: 0.2748\n",
      "Epoch 5/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9470 - loss: 0.1625 - val_accuracy: 0.9028 - val_loss: 0.2926\n",
      "Epoch 6/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9536 - loss: 0.1547 - val_accuracy: 0.9044 - val_loss: 0.3039\n",
      "Epoch 7/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9576 - loss: 0.1498 - val_accuracy: 0.9048 - val_loss: 0.3120\n",
      "Epoch 8/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.9598 - loss: 0.1467 - val_accuracy: 0.9008 - val_loss: 0.3255\n",
      "Epoch 9/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9585 - loss: 0.1458 - val_accuracy: 0.9018 - val_loss: 0.3361\n",
      "Epoch 10/10\n",
      "\u001B[1m625/625\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 6ms/step - accuracy: 0.9619 - loss: 0.1449 - val_accuracy: 0.9010 - val_loss: 0.3473\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x374629350>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"models/tfidf_2gram.keras\", save_best_only=True)]\n",
    "model.fit(x=tfidf_2gram_train_ds.cache(), validation_data=tfidf_2gram_val_ds.cache(), callbacks=callbacks, epochs=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T02:14:59.640028Z",
     "start_time": "2024-07-13T02:14:14.013741Z"
    }
   },
   "id": "f5d81894aabe8003"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 16ms/step - accuracy: 0.8984 - loss: 0.2749\n",
      "Test acc: 0.899\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"models/tfidf_2gram.keras\")\n",
    "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T02:15:14.573382Z",
     "start_time": "2024-07-13T02:15:01.033303Z"
    }
   },
   "id": "e03301bf00532a68"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exporting a model that processes raw strings\n",
    "Just create a new model that reuses your TextVectorization layer and adds to it the model you just trained"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e08f5f01328065b"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(1,), dtype=\"string\")  # inference will be one string only\n",
    "processed_inputs = tfidf_text_vectorization(inputs)  # apply text preprocessing\n",
    "outputs = model(processed_inputs)  # apply the trained model\n",
    "inference_model = keras.Model(inputs, outputs)  # full pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T02:15:22.952533Z",
     "start_time": "2024-07-13T02:15:22.950865Z"
    }
   },
   "id": "16ddc25e3b086921"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.98 percent positive\n"
     ]
    }
   ],
   "source": [
    "raw_text_data = tf.convert_to_tensor([\n",
    "    [\"That was an excellent movie, I loved it.\"],\n",
    "])\n",
    "predictions = inference_model(raw_text_data)\n",
    "print(f\"{float(predictions[0] * 100):.2f} percent positive\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T02:44:18.042670Z",
     "start_time": "2024-07-13T02:44:17.963925Z"
    }
   },
   "id": "5d7458d49440d5ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Processing words as a sequence: The sequence model approach\n",
    "Instead of manually crafting order-based features (like in N-Grams), we exposed the model to raw word sequences and let it figure out such features on its own. This is what sequence models are about.\n",
    "\n",
    "To implement a sequence model, you’d start by representing your input samples as sequences of integer indices (one integer standing for one word). Then, you’d map each integer to a vector to obtain vector sequences. Finally, you’d feed these sequences of vectors into a stack of layers that could cross-correlate features from adjacent vectors, such as a 1D convnet, an RNN, or a Transformer.\n",
    "\n",
    "For some time around 2016–2017, bidirectional RNNs (in particular, **bidirectional LSTMs**) were considered to be the state of the art for sequence modeling. Nowadays, sequence modeling is almost universally done with **Transformers**.\n",
    "\n",
    "Oddly, one-dimensional convnets were never very popular in NLP, **even though, in my own experience, a residual stack of depthwise-separable 1D convolutions can often achieve comparable performance to a bidirectional LSTM, at a greatly reduced computational cost**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8a807ee3babe2e1"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 19:47:23.000000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  2  19   7 765   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(500,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "max_length = 500\n",
    "max_tokens = 20_000\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)  # extract the text from the train dataset and ignore targets\n",
    "text_vectorization = keras.layers.TextVectorization(\n",
    "    # In order to keep a manageable input size, we’ll truncate the inputs after the first 500 words. Only used with output_mode=int\n",
    "    output_sequence_length=max_length,\n",
    "    output_mode=\"int\",\n",
    "    max_tokens=max_tokens\n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "test_sentence = \"the movie is fantastic\"\n",
    "encoded_sentence = text_vectorization(test_sentence)\n",
    "print(encoded_sentence)\n",
    "# Notice how it's already padded the output to be 500 items\n",
    "# Remember that each number in the output is and index of where this word lies in the total number of tokens. \n",
    "# Lower number means that it is more frequent ('the' is the second most frequent, 'is' 7th, 'movie' 19th)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T00:47:30.426171Z",
     "start_time": "2024-07-15T00:47:22.863803Z"
    }
   },
   "id": "9e6bc246462545cf"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T01:06:26.392848Z",
     "start_time": "2024-07-15T01:06:26.286381Z"
    }
   },
   "id": "64f9840cf62000b5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional_1\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m500\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lambda (\u001B[38;5;33mLambda\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m500\u001B[0m, \u001B[38;5;34m20000\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001B[38;5;33mBidirectional\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │     \u001B[38;5;34m5,128,448\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m65\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,128,448</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m5,128,513\u001B[0m (19.56 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,128,513</span> (19.56 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m5,128,513\u001B[0m (19.56 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,128,513</span> (19.56 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# there is an error in the author's notebook. \n",
    "inputs = keras.Input(shape=(500,), dtype=\"int64\")\n",
    "one_hot = tf.keras.layers.Lambda(lambda x: tf.one_hot(x, depth=max_tokens), output_shape=(500, max_tokens))(inputs)\n",
    "x = keras.layers.Bidirectional(keras.layers.LSTM(32))(one_hot)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T23:53:21.764913Z",
     "start_time": "2024-07-13T23:53:21.599542Z"
    }
   },
   "id": "d9b0de8c33425673"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=models/lambda_one_hot_bidir_lstm.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels/lambda_one_hot_bidir_lstm.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m, save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)]\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# model.fit(int_train_ds, callbacks=callbacks, validation_data=int_val_ds, epochs=10)\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodels/lambda_one_hot_bidir_lstm.keras\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mevaluate(int_test_ds)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Ran this code on Google colab. Accuracy is 87%. Took a long time.\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/DNNResearchProject/venv/lib/python3.11/site-packages/keras/src/saving/saving_api.py:185\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m legacy_h5_format\u001B[38;5;241m.\u001B[39mload_model_from_hdf5(filepath)\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.keras\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    186\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile not found: filepath=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    187\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease ensure the file is an accessible `.keras` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    188\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzip file.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    189\u001B[0m     )\n\u001B[1;32m    190\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    191\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    192\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile format not supported: filepath=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    193\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKeras 3 only supports V3 `.keras` files and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    202\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmight have a different name).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    203\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: File not found: filepath=models/lambda_one_hot_bidir_lstm.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(\"models/lambda_one_hot_bidir_lstm.keras\", save_best_only=True)]\n",
    "# model.fit(int_train_ds, callbacks=callbacks, validation_data=int_val_ds, epochs=10)\n",
    "model = keras.models.load_model(\"models/lambda_one_hot_bidir_lstm.keras\")\n",
    "print(f\"{model.evaluate(int_test_ds)[1]:.3f}\")\n",
    "# Ran this code on Google colab. Accuracy is 87%. Took a long time."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T02:35:09.228098Z",
     "start_time": "2024-07-14T02:35:09.182163Z"
    }
   },
   "id": "6baf161e8825b5cf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding word embeddings\n",
    "When using one-hot encoding, you make an assumption. That assumption is that the different tokens you’re encoding are all independent of each other: indeed, one-hot vectors are all orthogonal to one another. Which is wrong!!\n",
    "\n",
    "To get a bit more abstract, **the geometric relationship between two word vectors should reflect the semantic relationship between these words.**\n",
    "For instance, in a reasonable word vector space, you would expect synonyms to be embedded into similar word vectors, and in general, you would expect the geometric distance (such as the cosine distance or L2 distance) between any two word vectors to relate to the “semantic distance” between the associated words.\n",
    "\n",
    "**Word embeddings* are low-dimensional floating-point vectors (dense vectors)\n",
    "**Word embeddings** can be 256-dimensional, 512-dimensional, or 1,024-dimensional when dealing with very large vocabularies.\n",
    "**Word embeddings** pack more information into far fewer dimensions.\n",
    "**Word embeddings** are structured representations, and their structure is learned from data. Similar words get embedded in close locations,\n",
    "\n",
    "![alt text](static/word_embeddings.png \"word_embeddings\")\n",
    "\n",
    "In a 2D plane, some semantic relationships between these words can be encoded as geometric transformations.\n",
    "- From cat to tiger and from dog to wolf: “from pet to wild animal” vector.\n",
    "- From dog to cat and from wolf to tiger “from canine to feline” vector.\n",
    "\n",
    "![alt text](static/2d_word_embedding.png \"2d_word_embeddings\")\n",
    "\n",
    "Different Example:\n",
    "By adding a “female” vector to the vector “king,” we obtain the vector “queen.” By adding a “plural” vector, we obtain “kings.”\n",
    "\n",
    "#### Two ways to learn word embeddings\n",
    "- Similar to learning weights in a Neural Network\n",
    "- Load a precomputed (pretrained) word vector. \n",
    "\n",
    "**RULE: What makes a good word-embedding space depends heavily on your task**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9498d96b1b193597"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding Layer\n",
    "The Embedding layer is best understood as a dictionary that maps integer indices (which stand for specific words) to dense vectors. It takes integers as input, looks up these integers in an internal dictionary, and returns the associated vectors. \n",
    "```\n",
    "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)\n",
    "```\n",
    "**The Embedding layer** takes at least two arguments: the number of possible tokens and the dimensionality of the embeddings (here, 256)\n",
    "**The Embedding layer** takes as input a rank-2 tensor of integers, of shape `(batch_size, sequence_length)`, where each entry is a sequence of integers. The layer then returns a 3D floating-point tensor of shape `(batch_size, sequence_length, embedding_ dimensionality)`.\n",
    "Word vectors are initially random, then gradually adjusted via **backpropagation**."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "373a20f6d2b37d69"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 500)]             0         \n",
      "                                                                 \n",
      " embeddings_layer (Embeddin  (None, 500, 256)          5120000   \n",
      " g)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 64)                73984     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5194049 (19.81 MB)\n",
      "Trainable params: 5194049 (19.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "625/625 [==============================] - 112s 173ms/step - loss: 0.4701 - accuracy: 0.7868 - val_loss: 0.4697 - val_accuracy: 0.8072\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 136s 218ms/step - loss: 0.3052 - accuracy: 0.8858 - val_loss: 0.3024 - val_accuracy: 0.8878\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 135s 215ms/step - loss: 0.2351 - accuracy: 0.9153 - val_loss: 0.3114 - val_accuracy: 0.8844\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 86s 137ms/step - loss: 0.1916 - accuracy: 0.9330 - val_loss: 0.3027 - val_accuracy: 0.8934\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 102s 163ms/step - loss: 0.1551 - accuracy: 0.9468 - val_loss: 0.3406 - val_accuracy: 0.8912\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x318ce0c50>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256, name=\"embeddings_layer\")(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"models/embeddings_bidir_lstm.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=5, callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T14:19:09.267033Z",
     "start_time": "2024-07-14T14:09:35.919192Z"
    }
   },
   "id": "f68bd850f36017d7"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 31s 37ms/step - loss: 0.3612 - accuracy: 0.8672\n",
      "Test acc: 0.867\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"models/embeddings_bidir_lstm.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T14:24:13.810418Z",
     "start_time": "2024-07-14T14:23:40.689792Z"
    }
   },
   "id": "191436257d31462"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Output of embeddings_layer : [[[ 0.01360201  0.01767087  0.00328842 ...  0.01169621 -0.04574747\n",
      "    0.01518579]\n",
      "  [-0.04140052 -0.01244501  0.03076882 ...  0.00277484  0.04939148\n",
      "   -0.01400608]\n",
      "  [ 0.02322518 -0.04022496  0.00818865 ...  0.02046797  0.02836032\n",
      "    0.04751245]\n",
      "  ...\n",
      "  [-0.00334531  0.04427297 -0.0595779  ...  0.03713576  0.01749754\n",
      "   -0.02225276]\n",
      "  [-0.00334531  0.04427297 -0.0595779  ...  0.03713576  0.01749754\n",
      "   -0.02225276]\n",
      "  [-0.00334531  0.04427297 -0.0595779  ...  0.03713576  0.01749754\n",
      "   -0.02225276]]\n",
      "\n",
      " [[ 0.09805202  0.07216296 -0.07133085 ... -0.1775976  -0.2420526\n",
      "   -0.11087494]\n",
      "  [-0.04140052 -0.01244501  0.03076882 ...  0.00277484  0.04939148\n",
      "   -0.01400608]\n",
      "  [-0.03173373 -0.03777039  0.01584751 ...  0.0070865  -0.00574558\n",
      "    0.03534818]\n",
      "  ...\n",
      "  [-0.00334531  0.04427297 -0.0595779  ...  0.03713576  0.01749754\n",
      "   -0.02225276]\n",
      "  [-0.00334531  0.04427297 -0.0595779  ...  0.03713576  0.01749754\n",
      "   -0.02225276]\n",
      "  [-0.00334531  0.04427297 -0.0595779  ...  0.03713576  0.01749754\n",
      "   -0.02225276]]]\n"
     ]
    }
   ],
   "source": [
    "desired_layer_name = 'embeddings_layer'\n",
    "desired_layer_output_model = keras.Model(inputs=model.input,\n",
    "                                         outputs=model.get_layer(desired_layer_name).output)\n",
    "\n",
    "test_sentence = [\"the movie is fantastic\", \"worst movie i have ever seen\"]\n",
    "input_data = text_vectorization(test_sentence)\n",
    "layer_output = desired_layer_output_model.predict(input_data)\n",
    "\n",
    "# Print the output of the desired layer\n",
    "print(\"Output of\", desired_layer_name, \":\", layer_output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T14:28:30.316549Z",
     "start_time": "2024-07-14T14:28:28.800161Z"
    }
   },
   "id": "91393d59a6f56d39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding Padding and Masking\n",
    "One thing that’s slightly hurting model performance here is that our input sequences are full of zeros. This comes from our use of the **output_sequence_length=max_length** option in TextVectorization (with max_length equal to 500): sentences longer than 500 tokens are truncated to a length of 500 tokens, and sentences shorter than 500 tokens are padded with zeros.\n",
    "\n",
    "Because of the Zeroes (padding), the information stored in the internal state of the RNN will gradually fade out as it gets exposed to these meaningless inputs.\n",
    "We need some way to tell the RNN that it should skip these iterations. There’s an API for that: **Masking.**\n",
    "\n",
    "The Embedding layer is capable of generating a “mask” that corresponds to its input data. This mask is a tensor of ones and zeros (or True/False booleans), of shape (batch_size, sequence_length), where the entry mask[i, t] indicates where timestep t of sample i should be skipped or not.\n",
    "\n",
    "By default, this option isn’t active—you can turn it on by passing mask_zero=True to your Embedding layer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3245d266c2a46e34"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"models/embeddings_bidir_lstm_with_masking.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=5, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"models/embeddings_bidir_lstm_with_masking.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")\n",
    "\n",
    "# Ran the code into another PC because my laptop couldn't handle it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1de8f5f604c4c0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Pretrained Word Embeddings\n",
    "When to use this solution?\n",
    "Sometimes you have so little training data available that you can’t use your data alone to learn an appropriate task-specific embedding of your vocabulary. In such cases, instead of learning word embeddings jointly with the problem you want to solve, you can load embedding vectors from a precomputed embedding space that you know is highly structured and exhibits useful properties—one that captures generic aspects of language structure.\n",
    "\n",
    "It's very similar to use a pretrained ConvNet model.\n",
    "\n",
    "Such word embeddings are generally computed using word-occurrence statistics (observations about what words co-occur in sentences or documents), using a variety of techniques, some involving neural networks, others not.\n",
    "\n",
    "The Word2Vec algorithm (https://code.google.com/archive/p/word2vec): one of the most famous pre-trained word-embeddings.\n",
    "Global Vectors for Word Representation (GloVe, https://nlp.stanford.edu/projects/glove)\n",
    "\n",
    "We'll start with **GloVe**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86d3f6e0fc5763e1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-14 18:03:10--  http://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\r\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\r\n",
      "--2024-07-14 18:03:10--  https://nlp.stanford.edu/data/glove.6B.zip\r\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\r\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\r\n",
      "--2024-07-14 18:03:11--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\r\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\r\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 862182613 (822M) [application/zip]\r\n",
      "Saving to: ‘./data/glove.6B.zip’\r\n",
      "\r\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.60MB/s    in 2m 40s  \r\n",
      "\r\n",
      "2024-07-14 18:05:51 (5.15 MB/s) - ‘./data/glove.6B.zip’ saved [862182613/862182613]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip -P ./data/\n",
    "!unzip -q ./data/glove.6B.zip -d ./data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T23:06:05.183951Z",
     "start_time": "2024-07-14T23:03:10.427770Z"
    }
   },
   "id": "9598193813c814af"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_to_glove_file = \"data/glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T00:47:55.415904Z",
     "start_time": "2024-07-15T00:47:51.478646Z"
    }
   },
   "id": "10508e60872d8071"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors, each has 100 embedding.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(embeddings_index)} word vectors, each has {len(embeddings_index['hello'])} embedding.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T00:48:08.467243Z",
     "start_time": "2024-07-15T00:48:08.443727Z"
    }
   },
   "id": "5b64dc1db2d0ceb8"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.681131\n",
      "0.87980753\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(u, v):\n",
    "    # Measure how far embeddings from each other. Higher number means not similar\n",
    "    return np.sqrt(np.sum((u - v) ** 2))\n",
    "\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    # Measure how similar embeddings to each other. Higher number means more similar\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "\n",
    "print(euclidean_distance(embeddings_index[\"cat\"], embeddings_index[\"dog\"]))\n",
    "print(cosine_similarity(embeddings_index[\"cat\"], embeddings_index[\"dog\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T00:48:10.691660Z",
     "start_time": "2024-07-15T00:48:10.683772Z"
    }
   },
   "id": "e92fe1652cd000ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    " To load an embedding matrix that you can load to an Embedding layer, it must be a matrix of shape (max_words, embedding_dim), where each entry i contains the embedding_dim-dimensional vector for the word of index i in the reference word index (built during tokenization)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae8d50aa95297dc1"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim))  # max token=20_000 and embedding_dim=100\n",
    "\n",
    "for i, word in enumerate(vocabulary):\n",
    "    embedding_vector = embeddings_index.get(word, np.zeros(100))\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T01:03:04.842560Z",
     "start_time": "2024-07-15T01:03:04.770984Z"
    }
   },
   "id": "7ba7a76b6e079008"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# We use a Constant initializer to load the pretrained embeddings in an Embedding layer. \n",
    "# To not disrupt the pretrained representations during training, we freeze the layer via trainable=False\n",
    "embedding_layer = layers.Embedding(\n",
    "    max_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    "    mask_zero=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T01:03:58.588937Z",
     "start_time": "2024-07-15T01:03:58.568959Z"
    }
   },
   "id": "90516e3ccafc85c8"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 500)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       multiple                  2000000   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 64)                34048     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2034113 (7.76 MB)\n",
      "Trainable params: 34113 (133.25 KB)\n",
      "Non-trainable params: 2000000 (7.63 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "625/625 [==============================] - 73s 111ms/step - loss: 0.6935 - accuracy: 0.5088 - val_loss: 0.6891 - val_accuracy: 0.5072\n",
      "Epoch 2/15\n",
      "625/625 [==============================] - 68s 108ms/step - loss: 0.6889 - accuracy: 0.5155 - val_loss: 0.6880 - val_accuracy: 0.5204\n",
      "Epoch 3/15\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.6738 - accuracy: 0.5659 - val_loss: 0.6444 - val_accuracy: 0.6774\n",
      "Epoch 4/15\n",
      "625/625 [==============================] - 63s 100ms/step - loss: 0.6572 - accuracy: 0.5913 - val_loss: 0.6008 - val_accuracy: 0.6744\n",
      "Epoch 5/15\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.6185 - accuracy: 0.6676 - val_loss: 0.6091 - val_accuracy: 0.6980\n",
      "Epoch 6/15\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.6010 - accuracy: 0.6845 - val_loss: 0.5620 - val_accuracy: 0.7380\n",
      "Epoch 7/15\n",
      "625/625 [==============================] - 54s 86ms/step - loss: 0.5752 - accuracy: 0.7163 - val_loss: 0.5757 - val_accuracy: 0.7438\n",
      "Epoch 8/15\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.5688 - accuracy: 0.7150 - val_loss: 0.5305 - val_accuracy: 0.7400\n",
      "Epoch 9/15\n",
      "625/625 [==============================] - 62s 99ms/step - loss: 0.5476 - accuracy: 0.7281 - val_loss: 0.5343 - val_accuracy: 0.7592\n",
      "Epoch 10/15\n",
      "625/625 [==============================] - 92s 147ms/step - loss: 0.5332 - accuracy: 0.7485 - val_loss: 0.5054 - val_accuracy: 0.7758\n",
      "Epoch 11/15\n",
      "625/625 [==============================] - 67s 107ms/step - loss: 0.5257 - accuracy: 0.7440 - val_loss: 0.5077 - val_accuracy: 0.7794\n",
      "Epoch 12/15\n",
      "625/625 [==============================] - 67s 107ms/step - loss: 0.5175 - accuracy: 0.7527 - val_loss: 0.5109 - val_accuracy: 0.7820\n",
      "Epoch 13/15\n",
      "625/625 [==============================] - 56s 89ms/step - loss: 0.5050 - accuracy: 0.7630 - val_loss: 0.5074 - val_accuracy: 0.7028\n",
      "Epoch 14/15\n",
      "625/625 [==============================] - 60s 96ms/step - loss: 0.5012 - accuracy: 0.7610 - val_loss: 0.4877 - val_accuracy: 0.7610\n",
      "Epoch 15/15\n",
      "625/625 [==============================] - 52s 83ms/step - loss: 0.4918 - accuracy: 0.7721 - val_loss: 0.4881 - val_accuracy: 0.7954\n",
      "782/782 [==============================] - 36s 44ms/step - loss: 0.5131 - accuracy: 0.7533\n",
      "Test acc: 0.753\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(max_length, ), dtype=\"int64\")\n",
    "embedded = embedding_layer(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"models/glove_embeddings_sequence_model.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=15, callbacks=callbacks)\n",
    "model = keras.models.load_model(\"models/glove_embeddings_sequence_model.keras\")\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-15T01:29:38.826621Z",
     "start_time": "2024-07-15T01:13:00.595989Z"
    }
   },
   "id": "30ba943c0869102"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d5dfaf3c3da32bf4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5f7e6694a22ce87d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
